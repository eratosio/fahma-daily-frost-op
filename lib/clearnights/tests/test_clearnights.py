

import unittest
import pandas as pd
import numpy as np
import os
import pytz

from clearnights.clearnights import ClearNights
from clearnights.evaluation import evaluation_tair_threshold

path = os.path.abspath(os.path.dirname(__file__))


class ClearNightsTests(unittest.TestCase):

    TEST_DATA_PATH = os.path.join(path, 'data')


    def test_stage1_variance(self):
        """
        This test ensures that the output generated by this module recreates the original notebook output for the clearnights v1 algorithm.

        :return:
        """
        tair_frost_threshold = 2
        processed_year = 2021

        locations = pd.read_csv(os.path.join(ClearNightsTests.TEST_DATA_PATH, 'reference_sites.csv'))

        output_results = []

        clearnights = ClearNights({})

        for index, row in locations[:].iterrows():

            if row['location_key'] == 'ynco':
                continue

            bom_reference_tair = self.load_station_tair(row['location_key'],
                                                        row['location_name_short'],
                                                        processed_year)

            lst = self.load_reference_site_lst_eratos(row['filename_key'], row['Latitude'], row['Longitude'])

            stage1_output_df = clearnights.process_location(lst, None, row['Longitude'], row['Latitude'])

            filename = "h8_raw_frostperiod_night_" + row['location_key'] + '_' + str(processed_year) + "_stage1.csv"
            stage1_filename = os.path.join(ClearNightsTests.TEST_DATA_PATH, 'stage1_output_tmp', filename)
            stage1_output_df_no_tz = stage1_output_df.copy()
            stage1_output_df_no_tz.index = stage1_output_df_no_tz.index.tz_localize(None)
            stage1_output_df_no_tz.to_csv(stage1_filename, index=True, header=True)

            output_results.append(evaluation_tair_threshold(stage1_output_df['lst_stage1'], bom_reference_tair, tair_frost_threshold))


        all_output_results = pd.concat(output_results, keys=locations['location_key']).droplevel(1)

        all_output_results.to_csv('all_output_results.csv')

        output_accuracy = all_output_results['overall_accuracy'].mean()
        print(f'Output mean accuracy (compared to Tair 2 degree threshold) of all sites: {output_accuracy}')


    def load_reference_site_lst_eratos(self, filename_key, latitude, longitude):
        """
        Load raw LST data pre extracted from Eratos Senaps from Bowen Drive.
        This data is included in the repo for portability.

        TODO: Provide option to refresh data via Eratos SDK.

        """
        eratos_subset = os.path.join(ClearNightsTests.TEST_DATA_PATH, 'eratos_lst_reference_sites', f'fahma.himawari.lst.raw.2km.{filename_key}_{latitude}_{longitude}.csv')
        lst = pd.read_csv(eratos_subset, skiprows=6, parse_dates=True,
                          index_col='timestamp')  # the first 6 rows are just metadata

        lst.rename({lst.columns.values[0]: 'lst_original'}, axis=1, inplace=True)

        return lst

    def load_station_tair(self, processed_location, station_key, processed_year):

        # TODO: how to deal with this special case?
        if processed_location == 'bars':
            # Boorowa has its own AWS
            # Load in the necessary datasets
            t_air_aws = pd.read_csv(os.path.join(ClearNightsTests.TEST_DATA_PATH, "bars_tair", "t_air_aws_data_10min.csv"), parse_dates=True,
                                    index_col='timestamp')

            t_air_aws.rename(
                columns={'boorowa.environdata.AWS1.MAXIMUM-Air-Temperature (148.6887, -34.4732)': 'air_temp'},
                inplace=True)

            tair = t_air_aws

        else:
            # TODO: load from senaps directly? will we have temporal coverage? create embedded unittests with data?
            # TODO: trace source of this data
            # TODO: add readme about provenance and reproducing this data source
            tair_bom = pd.read_pickle(os.path.join(ClearNightsTests.TEST_DATA_PATH, 'bom_tair_reference_sites', 'data_pkl/04_bom_air_temp.pkl'))

            nearest_tair = tair_bom.loc[station_key].copy()

            nearest_tair['date_time'] = pd.to_datetime(nearest_tair['date_time'])
            nearest_tair.set_index('date_time', inplace=True)

            tair = nearest_tair[nearest_tair.index.year.isin([processed_year])].copy()

        return tair



